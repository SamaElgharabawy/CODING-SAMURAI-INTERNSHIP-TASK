{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79dcf3a4",
   "metadata": {},
   "source": [
    "# FIRST : IMPORT LIBRARIES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4db6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17b22fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from  sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import autocorrect\n",
    "#from spellchecker import SpellChecker\n",
    "import torch\n",
    "#from transformers import BertTokenizer, BertModel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a00516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a34a05cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                                   review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df .info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad037b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f10962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40279b6a",
   "metadata": {},
   "source": [
    "# SECOND : PRE-PROCESSING & DATA CLEANING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cddd04f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4e9278",
   "metadata": {},
   "source": [
    "#### so since the they are equal and not imbalanced towards one sentiment so no need for undersampling or oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a430f9cd",
   "metadata": {},
   "source": [
    "## Lowercasing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf96f18",
   "metadata": {},
   "source": [
    " we apply lowercasing to ensure equal consideration for all letters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2973496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_text(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f718b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(lowercase_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f5e91db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089060b3",
   "metadata": {},
   "source": [
    "## Split the dataframe into feature and target dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "826d333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr= df['review']\n",
    "dfs = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa82fddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "dfs = label_encoder.fit_transform(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c325e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "333736ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SamaG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')  # Download the Punkt tokenizer models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1b2a122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one of the other reviewers has mentioned that ...\n",
       "1        a wonderful little production. <br /><br />the...\n",
       "2        i thought this was a wonderful way to spend ti...\n",
       "3        basically there's a family where a little boy ...\n",
       "4        petter mattei's \"love in the time of money\" is...\n",
       "                               ...                        \n",
       "49995    i thought this movie did a down right good job...\n",
       "49996    bad plot, bad dialogue, bad acting, idiotic di...\n",
       "49997    i am a catholic taught in parochial elementary...\n",
       "49998    i'm going to have to disagree with the previou...\n",
       "49999    no one expects the star trek movies to be high...\n",
       "Name: review, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5de24a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9140aa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 50000\n",
       "unique                                                49582\n",
       "top       loved today's show!!! it was a variety and not...\n",
       "freq                                                      5\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19913d6",
   "metadata": {},
   "source": [
    "## Remove all HTML tags , URLs , Special Characters , & Stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d343402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SamaG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the stopwords and print them\n",
    "stop_words = stopwords.words(\"english\")\n",
    "print(stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bf99731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove any URLs or email addresses\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "        text = re.sub(r'\\S+@\\S+', '', text)\n",
    "\n",
    "        # Remove any sequence of alphanumeric characters starting with 'URL'\n",
    "        text = re.sub(r'URL\\w+', '', text)\n",
    "\n",
    "        # Remove any non-alphanumeric characters\n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "        # Split the text into sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        preprocessed_sentences = []\n",
    "        for sentence in sentences:\n",
    "            words = nltk.word_tokenize(sentence)\n",
    "\n",
    "            # Remove any word contains numbers\n",
    "            words = [word for word in words if not re.match('\\w*\\d\\w*', word)]\n",
    "\n",
    "            # Remove any word that is a stop word except \"not\", \"Not\", \"IT\", and \"it\"\n",
    "            stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "            stop_words.discard('not')\n",
    "            stop_words.discard('Not')\n",
    "            stop_words.discard('it')\n",
    "            stop_words.discard('IT')\n",
    "            words = [word for word in words if word.lower() not in stop_words or word.lower() in {'not', 'it'}]\n",
    "\n",
    "            preprocessed_sentence = ' '.join(words)\n",
    "            preprocessed_sentences.append(preprocessed_sentence)\n",
    "\n",
    "        # Join the preprocessed sentences back together into a single string\n",
    "        cleaned_text = ' '.join(preprocessed_sentences)\n",
    "\n",
    "        return cleaned_text\n",
    "    else:\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24265a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr= dfr.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9710050",
   "metadata": {},
   "source": [
    "## Handling extra whitespace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81853959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_whitespace(text):\n",
    "    if isinstance(text, str):\n",
    "        # Replace one or more whitespace characters with a single space\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "        return text.strip()  # Remove leading and trailing whitespace\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f01d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr = dfr.apply(remove_extra_whitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd96765d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 50000\n",
       "unique                                                49579\n",
       "top       loved todays show it variety not solely cookin...\n",
       "freq                                                      5\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0b06425",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr2 = pd.DataFrame(data=dfr.values, columns=['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13147ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching oz episode yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production br br filming tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job it wasnt creative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>catholic taught parochial elementary schools n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im going disagree previous comment side maltin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects star trek movies high art fans exp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews\n",
       "0      one reviewers mentioned watching oz episode yo...\n",
       "1      wonderful little production br br filming tech...\n",
       "2      thought wonderful way spend time hot summer we...\n",
       "3      basically theres family little boy jake thinks...\n",
       "4      petter matteis love time money visually stunni...\n",
       "...                                                  ...\n",
       "49995  thought movie right good job it wasnt creative...\n",
       "49996  bad plot bad dialogue bad acting idiotic direc...\n",
       "49997  catholic taught parochial elementary schools n...\n",
       "49998  im going disagree previous comment side maltin...\n",
       "49999  one expects star trek movies high art fans exp...\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62357cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>word_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching oz episode yo...</td>\n",
       "      <td>[one, reviewers, mentioned, watching, oz, epis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production br br filming tech...</td>\n",
       "      <td>[wonderful, little, production, br, br, filmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>[basically, theres, family, little, boy, jake,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job it wasnt creative...</td>\n",
       "      <td>[thought, movie, right, good, job, it, wasnt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>catholic taught parochial elementary schools n...</td>\n",
       "      <td>[catholic, taught, parochial, elementary, scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im going disagree previous comment side maltin...</td>\n",
       "      <td>[im, going, disagree, previous, comment, side,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects star trek movies high art fans exp...</td>\n",
       "      <td>[one, expects, star, trek, movies, high, art, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  \\\n",
       "0      one reviewers mentioned watching oz episode yo...   \n",
       "1      wonderful little production br br filming tech...   \n",
       "2      thought wonderful way spend time hot summer we...   \n",
       "3      basically theres family little boy jake thinks...   \n",
       "4      petter matteis love time money visually stunni...   \n",
       "...                                                  ...   \n",
       "49995  thought movie right good job it wasnt creative...   \n",
       "49996  bad plot bad dialogue bad acting idiotic direc...   \n",
       "49997  catholic taught parochial elementary schools n...   \n",
       "49998  im going disagree previous comment side maltin...   \n",
       "49999  one expects star trek movies high art fans exp...   \n",
       "\n",
       "                                             word_tokens  \n",
       "0      [one, reviewers, mentioned, watching, oz, epis...  \n",
       "1      [wonderful, little, production, br, br, filmin...  \n",
       "2      [thought, wonderful, way, spend, time, hot, su...  \n",
       "3      [basically, theres, family, little, boy, jake,...  \n",
       "4      [petter, matteis, love, time, money, visually,...  \n",
       "...                                                  ...  \n",
       "49995  [thought, movie, right, good, job, it, wasnt, ...  \n",
       "49996  [bad, plot, bad, dialogue, bad, acting, idioti...  \n",
       "49997  [catholic, taught, parochial, elementary, scho...  \n",
       "49998  [im, going, disagree, previous, comment, side,...  \n",
       "49999  [one, expects, star, trek, movies, high, art, ...  \n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#words = word_tokenize(dfr)\n",
    "dfr2['word_tokens'] = dfr2['reviews'].apply(word_tokenize)\n",
    "dfr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79dfb07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2a6298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b99acd8",
   "metadata": {},
   "source": [
    "## Expand contractions to their full forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24e5471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = {\n",
    "    \"can't\": \"cannot\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"n't\": \" not\",\n",
    "    \"'s\": \" is\",\n",
    "    \"'re\": \" are\",\n",
    "    \"'d\": \" would\",\n",
    "    \"'ll\": \" will\",\n",
    "    \"'t\": \" not\",\n",
    "    \"'ve\": \" have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c0000e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_contractions(text_series, contractions_dict):\n",
    "    expanded_text = text_series.apply(lambda x: ' '.join([contractions_dict[word] if word in contractions_dict else word for word in x]))\n",
    "    return expanded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "584fd5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        one reviewers mentioned watching oz episode yo...\n",
       "1        wonderful little production br br filming tech...\n",
       "2        thought wonderful way spend time hot summer we...\n",
       "3        basically theres family little boy jake thinks...\n",
       "4        petter matteis love time money visually stunni...\n",
       "                               ...                        \n",
       "49995    thought movie right good job it wasnt creative...\n",
       "49996    bad plot bad dialogue bad acting idiotic direc...\n",
       "49997    catholic taught parochial elementary schools n...\n",
       "49998    im going disagree previous comment side maltin...\n",
       "49999    one expects star trek movies high art fans exp...\n",
       "Name: word_tokens, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_text = expand_contractions(dfr2['word_tokens'], contractions_dict)\n",
    "expanded_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "770a6d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>word_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching oz episode yo...</td>\n",
       "      <td>[one, reviewers, mentioned, watching, oz, epis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production br br filming tech...</td>\n",
       "      <td>[wonderful, little, production, br, br, filmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>[basically, theres, family, little, boy, jake,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job it wasnt creative...</td>\n",
       "      <td>[thought, movie, right, good, job, it, wasnt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>catholic taught parochial elementary schools n...</td>\n",
       "      <td>[catholic, taught, parochial, elementary, scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im going disagree previous comment side maltin...</td>\n",
       "      <td>[im, going, disagree, previous, comment, side,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects star trek movies high art fans exp...</td>\n",
       "      <td>[one, expects, star, trek, movies, high, art, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  \\\n",
       "0      one reviewers mentioned watching oz episode yo...   \n",
       "1      wonderful little production br br filming tech...   \n",
       "2      thought wonderful way spend time hot summer we...   \n",
       "3      basically theres family little boy jake thinks...   \n",
       "4      petter matteis love time money visually stunni...   \n",
       "...                                                  ...   \n",
       "49995  thought movie right good job it wasnt creative...   \n",
       "49996  bad plot bad dialogue bad acting idiotic direc...   \n",
       "49997  catholic taught parochial elementary schools n...   \n",
       "49998  im going disagree previous comment side maltin...   \n",
       "49999  one expects star trek movies high art fans exp...   \n",
       "\n",
       "                                             word_tokens  \n",
       "0      [one, reviewers, mentioned, watching, oz, epis...  \n",
       "1      [wonderful, little, production, br, br, filmin...  \n",
       "2      [thought, wonderful, way, spend, time, hot, su...  \n",
       "3      [basically, theres, family, little, boy, jake,...  \n",
       "4      [petter, matteis, love, time, money, visually,...  \n",
       "...                                                  ...  \n",
       "49995  [thought, movie, right, good, job, it, wasnt, ...  \n",
       "49996  [bad, plot, bad, dialogue, bad, acting, idioti...  \n",
       "49997  [catholic, taught, parochial, elementary, scho...  \n",
       "49998  [im, going, disagree, previous, comment, side,...  \n",
       "49999  [one, expects, star, trek, movies, high, art, ...  \n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b483e8",
   "metadata": {},
   "source": [
    "## Remove duplicates (except \"not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b717e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(text):\n",
    "    if isinstance(text, list):\n",
    "        word_list = text\n",
    "    elif isinstance(text, str):\n",
    "        word_list = text.split()\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "    unique_words = []\n",
    "    for i, word in enumerate(word_list):\n",
    "        if word not in unique_words:\n",
    "            unique_words.append(word)\n",
    "        elif i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            unique_words[-1] += ' ' + word\n",
    "    \n",
    "    if isinstance(text, list):\n",
    "        return unique_words\n",
    "    elif isinstance(text, str):\n",
    "        return ' '.join(unique_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1efdd5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr2['reviews'] = dfr2['reviews'].apply(remove_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d07ab93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>word_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching oz episode yo...</td>\n",
       "      <td>[one, reviewers, mentioned, watching, oz, epis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production br br filming tech...</td>\n",
       "      <td>[wonderful, little, production, br, br, filmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>[basically, theres, family, little, boy, jake,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job it wasnt creative...</td>\n",
       "      <td>[thought, movie, right, good, job, it, wasnt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>catholic taught parochial elementary schools n...</td>\n",
       "      <td>[catholic, taught, parochial, elementary, scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im going disagree previous comment side maltin...</td>\n",
       "      <td>[im, going, disagree, previous, comment, side,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects star trek movies high art fans exp...</td>\n",
       "      <td>[one, expects, star, trek, movies, high, art, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  \\\n",
       "0      one reviewers mentioned watching oz episode yo...   \n",
       "1      wonderful little production br br filming tech...   \n",
       "2      thought wonderful way spend time hot summer we...   \n",
       "3      basically theres family little boy jake thinks...   \n",
       "4      petter matteis love time money visually stunni...   \n",
       "...                                                  ...   \n",
       "49995  thought movie right good job it wasnt creative...   \n",
       "49996  bad plot bad dialogue bad acting idiotic direc...   \n",
       "49997  catholic taught parochial elementary schools n...   \n",
       "49998  im going disagree previous comment side maltin...   \n",
       "49999  one expects star trek movies high art fans exp...   \n",
       "\n",
       "                                             word_tokens  \n",
       "0      [one, reviewers, mentioned, watching, oz, epis...  \n",
       "1      [wonderful, little, production, br, br, filmin...  \n",
       "2      [thought, wonderful, way, spend, time, hot, su...  \n",
       "3      [basically, theres, family, little, boy, jake,...  \n",
       "4      [petter, matteis, love, time, money, visually,...  \n",
       "...                                                  ...  \n",
       "49995  [thought, movie, right, good, job, it, wasnt, ...  \n",
       "49996  [bad, plot, bad, dialogue, bad, acting, idioti...  \n",
       "49997  [catholic, taught, parochial, elementary, scho...  \n",
       "49998  [im, going, disagree, previous, comment, side,...  \n",
       "49999  [one, expects, star, trek, movies, high, art, ...  \n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84b9bfe",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82d43b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    if isinstance(text, str):\n",
    "        # Split the text into sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        # Lemmatize each word in each sentence\n",
    "        lemmatized_sentences = []\n",
    "        for sentence in sentences:\n",
    "            words = nltk.word_tokenize(sentence)\n",
    "            lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "            lemmatized_sentences.append(' '.join(lemmatized_words))\n",
    "\n",
    "        # Join the lemmatized sentences back together into a single string\n",
    "        lemmatized_text = ' '.join(lemmatized_sentences)\n",
    "        return lemmatized_text\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "721887c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfr2['reviews'] = dfr2['reviews'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e13795e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>word_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching oz episode you...</td>\n",
       "      <td>[one, reviewers, mentioned, watching, oz, epis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production br br filming tech...</td>\n",
       "      <td>[wonderful, little, production, br, br, filmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there family little boy jake think t...</td>\n",
       "      <td>[basically, theres, family, little, boy, jake,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>thought movie right good job it wasnt creative...</td>\n",
       "      <td>[thought, movie, right, good, job, it, wasnt, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>[bad, plot, bad, dialogue, bad, acting, idioti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>catholic taught parochial elementary school nu...</td>\n",
       "      <td>[catholic, taught, parochial, elementary, scho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>im going disagree previous comment side maltin...</td>\n",
       "      <td>[im, going, disagree, previous, comment, side,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>one expects star trek movie high art fan expec...</td>\n",
       "      <td>[one, expects, star, trek, movies, high, art, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  \\\n",
       "0      one reviewer mentioned watching oz episode you...   \n",
       "1      wonderful little production br br filming tech...   \n",
       "2      thought wonderful way spend time hot summer we...   \n",
       "3      basically there family little boy jake think t...   \n",
       "4      petter matteis love time money visually stunni...   \n",
       "...                                                  ...   \n",
       "49995  thought movie right good job it wasnt creative...   \n",
       "49996  bad plot bad dialogue bad acting idiotic direc...   \n",
       "49997  catholic taught parochial elementary school nu...   \n",
       "49998  im going disagree previous comment side maltin...   \n",
       "49999  one expects star trek movie high art fan expec...   \n",
       "\n",
       "                                             word_tokens  \n",
       "0      [one, reviewers, mentioned, watching, oz, epis...  \n",
       "1      [wonderful, little, production, br, br, filmin...  \n",
       "2      [thought, wonderful, way, spend, time, hot, su...  \n",
       "3      [basically, theres, family, little, boy, jake,...  \n",
       "4      [petter, matteis, love, time, money, visually,...  \n",
       "...                                                  ...  \n",
       "49995  [thought, movie, right, good, job, it, wasnt, ...  \n",
       "49996  [bad, plot, bad, dialogue, bad, acting, idioti...  \n",
       "49997  [catholic, taught, parochial, elementary, scho...  \n",
       "49998  [im, going, disagree, previous, comment, side,...  \n",
       "49999  [one, expects, star, trek, movies, high, art, ...  \n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3e2bd",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe3221e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ability  able  absolutely  accent  across  act  acted  acting  action  \\\n",
      "0            0     0           0       0       0    0      0       0       0   \n",
      "1            0     0           0       0       0    0      0       0       0   \n",
      "2            0     0           0       0       0    0      0       0       0   \n",
      "3            0     0           0       0       0    0      0       0       0   \n",
      "4            0     0           0       0       0    0      0       1       1   \n",
      "...        ...   ...         ...     ...     ...  ...    ...     ...     ...   \n",
      "49995        0     0           0       0       0    0      0       0       0   \n",
      "49996        0     0           0       0       0    0      0       1       0   \n",
      "49997        0     0           0       0       0    1      0       1       0   \n",
      "49998        0     0           0       0       1    0      0       0       0   \n",
      "49999        0     0           0       0       0    0      0       0       0   \n",
      "\n",
      "       actor  ...  year  yes  yet  york  youll  young  younger  youre  youve  \\\n",
      "0          0  ...     0    0    0     0      1      0        0      0      0   \n",
      "1          1  ...     0    0    0     0      0      0        0      0      0   \n",
      "2          0  ...     1    0    0     0      0      1        0      0      0   \n",
      "3          0  ...     0    0    0     0      0      0        0      1      0   \n",
      "4          0  ...     0    0    0     1      0      0        0      0      0   \n",
      "...      ...  ...   ...  ...  ...   ...    ...    ...      ...    ...    ...   \n",
      "49995      0  ...     0    0    0     0      0      0        0      0      0   \n",
      "49996      0  ...     0    0    0     0      0      0        0      0      0   \n",
      "49997      0  ...     0    0    0     0      0      0        0      0      0   \n",
      "49998      0  ...     0    0    0     0      0      0        0      0      0   \n",
      "49999      0  ...     0    0    0     0      1      0        0      0      0   \n",
      "\n",
      "       zombie  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           1  \n",
      "4           0  \n",
      "...       ...  \n",
      "49995       0  \n",
      "49996       0  \n",
      "49997       0  \n",
      "49998       0  \n",
      "49999       0  \n",
      "\n",
      "[50000 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "\n",
    "#We fit and transform the column of the data frame using the fit_transform() method of the count vectorizer. This creates a sparse matrix of term frequencies for each document in the corpus\n",
    "# fit and transform the using CountVectorizer\n",
    "bag_of_words = count_vectorizer.fit_transform(dfr2['reviews'])\n",
    "\n",
    "# get the feature names (unique words) from CountVectorizer\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "# print(feature_names)\n",
    "# create a new data frame using the bag of words matrix and feature names\n",
    "bow_df = pd.DataFrame(bag_of_words.toarray(), columns=feature_names)\n",
    "\n",
    "# print the resulting bag of words data frame\n",
    "print(bow_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40d44765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF feature matrix shape: (50000, 1000)\n",
      "       ability  able  absolutely  accent    across       act  acted    acting  \\\n",
      "0          0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.000000   \n",
      "1          0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.000000   \n",
      "2          0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.000000   \n",
      "3          0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.000000   \n",
      "4          0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.067468   \n",
      "...        ...   ...         ...     ...       ...       ...    ...       ...   \n",
      "49995      0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.000000   \n",
      "49996      0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.123777   \n",
      "49997      0.0   0.0         0.0     0.0  0.000000  0.115781    0.0  0.075652   \n",
      "49998      0.0   0.0         0.0     0.0  0.160979  0.000000    0.0  0.000000   \n",
      "49999      0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.000000   \n",
      "\n",
      "         action     actor  ...      year  yes  yet      york     youll  \\\n",
      "0      0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.091298   \n",
      "1      0.000000  0.092043  ...  0.000000  0.0  0.0  0.000000  0.000000   \n",
      "2      0.000000  0.000000  ...  0.102416  0.0  0.0  0.000000  0.000000   \n",
      "3      0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.000000   \n",
      "4      0.088739  0.000000  ...  0.000000  0.0  0.0  0.127001  0.000000   \n",
      "...         ...       ...  ...       ...  ...  ...       ...       ...   \n",
      "49995  0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.000000   \n",
      "49996  0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.000000   \n",
      "49997  0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.000000   \n",
      "49998  0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.000000   \n",
      "49999  0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.146106   \n",
      "\n",
      "         young  younger     youre  youve    zombie  \n",
      "0      0.00000      0.0  0.000000    0.0  0.000000  \n",
      "1      0.00000      0.0  0.000000    0.0  0.000000  \n",
      "2      0.12382      0.0  0.000000    0.0  0.000000  \n",
      "3      0.00000      0.0  0.121704    0.0  0.169975  \n",
      "4      0.00000      0.0  0.000000    0.0  0.000000  \n",
      "...        ...      ...       ...    ...       ...  \n",
      "49995  0.00000      0.0  0.000000    0.0  0.000000  \n",
      "49996  0.00000      0.0  0.000000    0.0  0.000000  \n",
      "49997  0.00000      0.0  0.000000    0.0  0.000000  \n",
      "49998  0.00000      0.0  0.000000    0.0  0.000000  \n",
      "49999  0.00000      0.0  0.000000    0.0  0.000000  \n",
      "\n",
      "[50000 rows x 1000 columns]\n",
      "(50000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Create a TF-IDF vectorizer object\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "\n",
    "# Fit the vectorizer object on the text column\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(dfr2['reviews'])\n",
    "\n",
    "# # Transform the text column into a sparse matrix of TF-IDF features\n",
    "# tfidf_features = tfidf_vectorizer.transform(df['all_info'])\n",
    "\n",
    "# Print the feature matrix shape\n",
    "print('TF-IDF feature matrix shape:', X_train_tfidf.shape)\n",
    "tfidf_df = pd.DataFrame(X_train_tfidf.toarray(), columns=feature_names)\n",
    "\n",
    "print(tfidf_df)\n",
    "print(tfidf_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f6209d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accent</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youre</th>\n",
       "      <th>youve</th>\n",
       "      <th>zombie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091298</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.12382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067468</td>\n",
       "      <td>0.088739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146106</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ability  able  absolutely  accent    across       act  acted    acting  \\\n",
       "0          0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.000000   \n",
       "1          0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.000000   \n",
       "2          0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.000000   \n",
       "3          0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.000000   \n",
       "4          0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.067468   \n",
       "...        ...   ...         ...     ...       ...       ...    ...       ...   \n",
       "49995      0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.000000   \n",
       "49996      0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.123777   \n",
       "49997      0.0   0.0         0.0     0.0  0.000000  0.115781    0.0  0.075652   \n",
       "49998      0.0   0.0         0.0     0.0  0.160979  0.000000    0.0  0.000000   \n",
       "49999      0.0   0.0         0.0     0.0  0.000000  0.000000    0.0  0.000000   \n",
       "\n",
       "         action     actor  ...      year  yes  yet      york     youll  \\\n",
       "0      0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.091298   \n",
       "1      0.000000  0.092043  ...  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "2      0.000000  0.000000  ...  0.102416  0.0  0.0  0.000000  0.000000   \n",
       "3      0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "4      0.088739  0.000000  ...  0.000000  0.0  0.0  0.127001  0.000000   \n",
       "...         ...       ...  ...       ...  ...  ...       ...       ...   \n",
       "49995  0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "49996  0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "49997  0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "49998  0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.000000   \n",
       "49999  0.000000  0.000000  ...  0.000000  0.0  0.0  0.000000  0.146106   \n",
       "\n",
       "         young  younger     youre  youve    zombie  \n",
       "0      0.00000      0.0  0.000000    0.0  0.000000  \n",
       "1      0.00000      0.0  0.000000    0.0  0.000000  \n",
       "2      0.12382      0.0  0.000000    0.0  0.000000  \n",
       "3      0.00000      0.0  0.121704    0.0  0.169975  \n",
       "4      0.00000      0.0  0.000000    0.0  0.000000  \n",
       "...        ...      ...       ...    ...       ...  \n",
       "49995  0.00000      0.0  0.000000    0.0  0.000000  \n",
       "49996  0.00000      0.0  0.000000    0.0  0.000000  \n",
       "49997  0.00000      0.0  0.000000    0.0  0.000000  \n",
       "49998  0.00000      0.0  0.000000    0.0  0.000000  \n",
       "49999  0.00000      0.0  0.000000    0.0  0.000000  \n",
       "\n",
       "[50000 rows x 1000 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2811613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42cde368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.reshape(50000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39267db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006299b7",
   "metadata": {},
   "source": [
    "## TRAIN-TEST SPLITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cc9c2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, dfs, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a36dbe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(bow_df, dfs, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b8592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26e83be0",
   "metadata": {},
   "source": [
    "## Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaf372a",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bfd9d80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using all the features:\n",
      "Accuracy: \n",
      " 0.8588\n",
      "Accuracy report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86      6217\n",
      "           1       0.86      0.87      0.86      6283\n",
      "\n",
      "    accuracy                           0.86     12500\n",
      "   macro avg       0.86      0.86      0.86     12500\n",
      "weighted avg       0.86      0.86      0.86     12500\n",
      "\n",
      "Confusion Matrix: \n",
      " [[5322  895]\n",
      " [ 846 5437]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Bag of words\n",
    "classifier = LogisticRegression(penalty='l2',solver='lbfgs',multi_class='ovr',class_weight='balanced')\n",
    "classifier.fit(X_train2 , y_train2)\n",
    "prediction2=classifier.predict(X_test2)\n",
    "#model_score = accuracy_score(y_train, prediction)\n",
    "model_score = accuracy_score(y_test2, prediction2)\n",
    "class_report=classification_report(y_test2, prediction2)\n",
    "# Print the accuracy report, scores and confusion matrix\n",
    "print(\"Logistic Regression using all the features:\")\n",
    "print(\"Accuracy:\",\"\\n\", model_score)\n",
    "print(\"Accuracy report:\",\"\\n\", class_report)\n",
    "print(\"Confusion Matrix:\",\"\\n\", confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2bb03600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression using all the features:\n",
      "Accuracy: \n",
      " 0.86072\n",
      "Accuracy report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      6217\n",
      "           1       0.86      0.87      0.86      6283\n",
      "\n",
      "    accuracy                           0.86     12500\n",
      "   macro avg       0.86      0.86      0.86     12500\n",
      "weighted avg       0.86      0.86      0.86     12500\n",
      "\n",
      "Confusion Matrix: \n",
      " [[5322  895]\n",
      " [ 846 5437]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TFIDF\n",
    "classifier = LogisticRegression(penalty='l2',solver='lbfgs',multi_class='ovr',class_weight='balanced')\n",
    "classifier.fit(X_train , y_train)\n",
    "prediction=classifier.predict(X_test)\n",
    "#model_score = accuracy_score(y_train, prediction)\n",
    "model_score = accuracy_score(y_test, prediction)\n",
    "class_report=classification_report(y_test, prediction)\n",
    "# Print the accuracy report, scores and confusion matrix\n",
    "print(\"Logistic Regression using all the features:\")\n",
    "print(\"Accuracy:\",\"\\n\", model_score)\n",
    "print(\"Accuracy report:\",\"\\n\", class_report)\n",
    "print(\"Confusion Matrix:\",\"\\n\", confusion_matrix(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d294482",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8e61a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of RF': 0.8164\n",
      "[[4801 1416]\n",
      " [ 879 5404]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.77      0.81      6217\n",
      "           1       0.79      0.86      0.82      6283\n",
      "\n",
      "    accuracy                           0.82     12500\n",
      "   macro avg       0.82      0.82      0.82     12500\n",
      "weighted avg       0.82      0.82      0.82     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TFIDF\n",
    "rfc = RandomForestClassifier(n_estimators=150, max_depth=15, min_samples_split=10)\n",
    "\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "conf_mat = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(\"accuracy of RF': {}\".format(accuracy_score(y_pred,y_test)))\n",
    "print(conf_mat)\n",
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de04c107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of RF': 0.8116\n",
      "[[4819 1398]\n",
      " [ 957 5326]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.80      6217\n",
      "           1       0.79      0.85      0.82      6283\n",
      "\n",
      "    accuracy                           0.81     12500\n",
      "   macro avg       0.81      0.81      0.81     12500\n",
      "weighted avg       0.81      0.81      0.81     12500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bag of words\n",
    "rfc = RandomForestClassifier(n_estimators=150, max_depth=15, min_samples_split=10)\n",
    "\n",
    "\n",
    "rfc.fit(X_train2, y_train2)\n",
    "\n",
    "\n",
    "y_pred2 = rfc.predict(X_test2)\n",
    "\n",
    "conf_mat = confusion_matrix(y_test2,y_pred2)\n",
    "\n",
    "print(\"accuracy of RF': {}\".format(accuracy_score(y_pred2,y_test2)))\n",
    "print(conf_mat)\n",
    "print(metrics.classification_report(y_test2,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebdcff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
